{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda7ed13",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "chars contained '$' and '3'. The former is a single typo and is fixed, the latter is included in a footer for \"3 KING HENRY VI\", the name of a play, and has been removed everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733b2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "notebook_location_dir = Path.cwd()\n",
    "project_root = notebook_location_dir.parent\n",
    "\n",
    "data_path = project_root / \"data\"\n",
    "\n",
    "with open(data_path / \"tinyshakespeare.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4c9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1114962\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f59f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4071a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !&',-.:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a94d6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 41, 48, 48, 51, 1, 56, 44, 41, 54, 41, 2]\n",
      "Hello there!\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "def encode(s: str) -> list[int]:\n",
    "    \"\"\"encoder: take a string, output a list of integers\"\"\"\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(ls: list[int]) -> str:\n",
    "    \"\"\"decoder: take a list of integers, output a string\"\"\"\n",
    "    return ''.join([itos[i] for i in ls]) # \n",
    "\n",
    "encoding = encode(\"Hello there!\")\n",
    "print(encoding)\n",
    "print(decode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82542748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coenrouwmaat/Python/Projects/ai-safety/gpt/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1114962]) torch.int64\n",
      "tensor([16, 45, 54, 55, 56,  1, 13, 45, 56, 45, 62, 41, 50,  8,  0, 12, 41, 42,\n",
      "        51, 54, 41,  1, 59, 41,  1, 52, 54, 51, 39, 41, 41, 40,  1, 37, 50, 61,\n",
      "         1, 42, 57, 54, 56, 44, 41, 54,  5,  1, 44, 41, 37, 54,  1, 49, 41,  1,\n",
      "        55, 52, 41, 37, 47,  7,  0,  0, 11, 48, 48,  8,  0, 29, 52, 41, 37, 47,\n",
      "         5,  1, 55, 52, 41, 37, 47,  7,  0,  0, 16, 45, 54, 55, 56,  1, 13, 45,\n",
      "        56, 45, 62, 41, 50,  8,  0, 35, 51, 57,  1, 37, 54, 41,  1, 37, 48, 48,\n",
      "         1, 54, 41, 55, 51, 48, 58, 41, 40,  1, 54, 37, 56, 44, 41, 54,  1, 56,\n",
      "        51,  1, 40, 45, 41,  1, 56, 44, 37, 50,  1, 56, 51,  1, 42, 37, 49, 45,\n",
      "        55, 44, 10,  0,  0, 11, 48, 48,  8,  0, 28, 41, 55, 51, 48, 58, 41, 40,\n",
      "         7,  1, 54, 41, 55, 51, 48, 58, 41, 40,  7,  0,  0, 16, 45, 54, 55, 56,\n",
      "         1, 13, 45, 56, 45, 62, 41, 50,  8,  0, 16, 45, 54, 55, 56,  5,  1, 61,\n",
      "        51, 57,  1, 47, 50, 51, 59,  1, 13, 37, 45, 57, 55,  1, 23, 37, 54, 39,\n",
      "        45, 57, 55,  1, 45, 55,  1, 39, 44, 45, 41, 42,  1, 41, 50, 41, 49, 61,\n",
      "         1, 56, 51,  1, 56, 44, 41,  1, 52, 41, 51, 52, 48, 41,  7,  0,  0, 11,\n",
      "        48, 48,  8,  0, 33, 41,  1, 47, 50, 51, 59,  4, 56,  5,  1, 59, 41,  1,\n",
      "        47, 50, 51, 59,  4, 56,  7,  0,  0, 16, 45, 54, 55, 56,  1, 13, 45, 56,\n",
      "        45, 62, 41, 50,  8,  0, 22, 41, 56,  1, 57, 55,  1, 47, 45, 48, 48,  1,\n",
      "        44, 45, 49,  5,  1, 37, 50, 40,  1, 59, 41,  4, 48, 48,  1, 44, 37, 58,\n",
      "        41,  1, 39, 51, 54, 50,  1, 37, 56,  1, 51, 57, 54,  1, 51, 59, 50,  1,\n",
      "        52, 54, 45, 39, 41,  7,  0, 19, 55,  4, 56,  1, 37,  1, 58, 41, 54, 40,\n",
      "        45, 39, 56, 10,  0,  0, 11, 48, 48,  8,  0, 24, 51,  1, 49, 51, 54, 41,\n",
      "         1, 56, 37, 48, 47, 45, 50, 43,  1, 51, 50,  4, 56,  9,  1, 48, 41, 56,\n",
      "         1, 45, 56,  1, 38, 41,  1, 40, 51, 50, 41,  8,  1, 37, 59, 37, 61,  5,\n",
      "         1, 37, 59, 37, 61,  2,  0,  0, 29, 41, 39, 51, 50, 40,  1, 13, 45, 56,\n",
      "        45, 62, 41, 50,  8,  0, 25, 50, 41,  1, 59, 51, 54, 40,  5,  1, 43, 51,\n",
      "        51, 40,  1, 39, 45, 56, 45, 62, 41, 50, 55,  7,  0,  0, 16, 45, 54, 55,\n",
      "        56,  1, 13, 45, 56, 45, 62, 41, 50,  8,  0, 33, 41,  1, 37, 54, 41,  1,\n",
      "        37, 39, 39, 51, 57, 50, 56, 41, 40,  1, 52, 51, 51, 54,  1, 39, 45, 56,\n",
      "        45, 62, 41, 50, 55,  5,  1, 56, 44, 41,  1, 52, 37, 56, 54, 45, 39, 45,\n",
      "        37, 50, 55,  1, 43, 51, 51, 40,  7,  0, 33, 44, 37, 56,  1, 37, 57, 56,\n",
      "        44, 51, 54, 45, 56, 61,  1, 55, 57, 54, 42, 41, 45, 56, 55,  1, 51, 50,\n",
      "         1, 59, 51, 57, 48, 40,  1, 54, 41, 48, 45, 41, 58, 41,  1, 57, 55,  8,\n",
      "         1, 45, 42,  1, 56, 44, 41, 61,  0, 59, 51, 57, 48, 40,  1, 61, 45, 41,\n",
      "        48, 40,  1, 57, 55,  1, 38, 57, 56,  1, 56, 44, 41,  1, 55, 57, 52, 41,\n",
      "        54, 42, 48, 57, 45, 56, 61,  5,  1, 59, 44, 45, 48, 41,  1, 45, 56,  1,\n",
      "        59, 41, 54, 41,  0, 59, 44, 51, 48, 41, 55, 51, 49, 41,  5,  1, 59, 41,\n",
      "         1, 49, 45, 43, 44, 56,  1, 43, 57, 41, 55, 55,  1, 56, 44, 41, 61,  1,\n",
      "        54, 41, 48, 45, 41, 58, 41, 40,  1, 57, 55,  1, 44, 57, 49, 37, 50, 41,\n",
      "        48, 61,  9,  0, 38, 57, 56,  1, 56, 44, 41, 61,  1, 56, 44, 45, 50, 47,\n",
      "         1, 59, 41,  1, 37, 54, 41,  1, 56, 51, 51,  1, 40, 41, 37, 54,  8,  1,\n",
      "        56, 44, 41,  1, 48, 41, 37, 50, 50, 41, 55, 55,  1, 56, 44, 37, 56,  0,\n",
      "        37, 42, 42, 48, 45, 39, 56, 55,  1, 57, 55,  5,  1, 56, 44, 41,  1, 51,\n",
      "        38, 46, 41, 39, 56,  1, 51, 42,  1, 51, 57, 54,  1, 49, 45, 55, 41, 54,\n",
      "        61,  5,  1, 45, 55,  1, 37, 55,  1, 37, 50,  0, 45, 50, 58, 41, 50, 56,\n",
      "        51, 54, 61,  1, 56, 51,  1, 52, 37, 54, 56, 45, 39, 57, 48, 37, 54, 45,\n",
      "        55, 41,  1, 56, 44, 41, 45, 54,  1, 37, 38, 57, 50, 40, 37, 50, 39, 41,\n",
      "         9,  1, 51, 57, 54,  0, 55, 57, 42, 42, 41, 54, 37, 50, 39, 41,  1, 45,\n",
      "        55,  1, 37,  1, 43, 37, 45, 50,  1, 56, 51,  1, 56, 44, 41, 49,  1, 22,\n",
      "        41, 56,  1, 57, 55,  1, 54, 41, 58, 41, 50, 43, 41,  1, 56, 44, 45, 55,\n",
      "         1, 59, 45, 56, 44,  0, 51, 57, 54,  1, 52, 45, 47, 41, 55,  5,  1, 41,\n",
      "        54, 41,  1, 59, 41,  1, 38, 41, 39, 51, 49, 41,  1, 54, 37, 47, 41, 55,\n",
      "         8,  1, 42, 51, 54,  1, 56, 44, 41,  1, 43, 51, 40, 55,  1, 47, 50, 51,\n",
      "        59,  1, 19,  0, 55, 52, 41, 37, 47,  1, 56, 44, 45, 55,  1, 45, 50,  1,\n",
      "        44, 57, 50, 43, 41, 54,  1, 42, 51, 54,  1, 38, 54, 41, 37, 40,  5,  1,\n",
      "        50, 51, 56,  1, 45, 50,  1, 56, 44, 45, 54, 55, 56,  1, 42, 51, 54,  1,\n",
      "        54, 41, 58, 41, 50, 43, 41,  7,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30df1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732c3f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 45, 54, 55, 56,  1, 13, 45, 56])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc2579c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([16]), the target is 45\n",
      "when input is tensor([16, 45]), the target is 54\n",
      "when input is tensor([16, 45, 54]), the target is 55\n",
      "when input is tensor([16, 45, 54, 55]), the target is 56\n",
      "when input is tensor([16, 45, 54, 55, 56]), the target is 1\n",
      "when input is tensor([16, 45, 54, 55, 56,  1]), the target is 13\n",
      "when input is tensor([16, 45, 54, 55, 56,  1, 13]), the target is 45\n",
      "when input is tensor([16, 45, 54, 55, 56,  1, 13, 45]), the target is 56\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b2846f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[41, 55,  1, 44, 45, 49,  1, 42],\n",
      "        [50, 51, 56,  1, 41, 50, 40, 57],\n",
      "        [59, 37, 47, 41,  1, 56, 45, 48],\n",
      "        [58, 41,  1, 40, 37, 54, 47,  1]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[55,  1, 44, 45, 49,  1, 42, 37],\n",
      "        [51, 56,  1, 41, 50, 40, 57, 54],\n",
      "        [37, 47, 41,  1, 56, 45, 48, 48],\n",
      "        [41,  1, 40, 37, 54, 47,  1, 40]])\n",
      "----\n",
      "when input is e, the target is s\n",
      "when input is es, the target is  \n",
      "when input is es , the target is h\n",
      "when input is es h, the target is i\n",
      "when input is es hi, the target is m\n",
      "when input is es him, the target is  \n",
      "when input is es him , the target is f\n",
      "when input is es him f, the target is a\n",
      "when input is n, the target is o\n",
      "when input is no, the target is t\n",
      "when input is not, the target is  \n",
      "when input is not , the target is e\n",
      "when input is not e, the target is n\n",
      "when input is not en, the target is d\n",
      "when input is not end, the target is u\n",
      "when input is not endu, the target is r\n",
      "when input is w, the target is a\n",
      "when input is wa, the target is k\n",
      "when input is wak, the target is e\n",
      "when input is wake, the target is  \n",
      "when input is wake , the target is t\n",
      "when input is wake t, the target is i\n",
      "when input is wake ti, the target is l\n",
      "when input is wake til, the target is l\n",
      "when input is v, the target is e\n",
      "when input is ve, the target is  \n",
      "when input is ve , the target is d\n",
      "when input is ve d, the target is a\n",
      "when input is ve da, the target is r\n",
      "when input is ve dar, the target is k\n",
      "when input is ve dark, the target is  \n",
      "when input is ve dark , the target is d\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))  # Random starting position in the data, sampled [batch_size] times\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {decode(context.tolist())}, the target is {itos[int(target)]}\")\n",
    "        # print(f\"when input is {context.tolist()}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58415fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[41, 55,  1, 44, 45, 49,  1, 42],\n",
      "        [50, 51, 56,  1, 41, 50, 40, 57],\n",
      "        [59, 37, 47, 41,  1, 56, 45, 48],\n",
      "        [58, 41,  1, 40, 37, 54, 47,  1]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 63])\n",
      "tensor(4.8558, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Ue;m:TYh\n",
      "LwajmRFdGSdcKjNW!aFGV!&,htCLTYFEPQ!xuWeyslIELK&PjN&\n",
      "mt&ZLldYmhy;ebIqeh\n",
      " -I-gN!BCFpRwj;mUigw\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # TODO: research further how this works\n",
    "\n",
    "    def forward(self, idx: Tensor, targets: Tensor | None = None) -> tuple[Tensor, Tensor]:\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits: Tensor = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape  # Batch size, Time steps, Channel (embedding size / # features)\n",
    "            logits = logits.view(B*T, C)  # TODO: intuitive explanation for this reshape\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx: Tensor, max_new_tokens: int) -> Tensor:\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))  # first item from batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5299144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c75c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.501077651977539\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())  # plateaus around 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ea9f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANGowint te wn in,\n",
      "\n",
      "Mait sthide ur whay! t g t'le fry,\n",
      "QUFoly, rense, f le powh termathus t heby gobelllaruce che ipar:\n",
      "ca mand onand th m Heerfit s be?\n",
      "KEEES: lll, clou held wal ju,\n",
      "Rothuly so, othe ny Hano ORinge en'sp trthe me, thisay plpsalle, INEThtyor ge s me.\n",
      "ORO: serdisthatod\n",
      "Whyothathase, cusee.\n",
      "Tord\n",
      "I pe.\n",
      "Pe;\n",
      "werue ize lime werey o ar Ise pad I\n",
      "KELAsupant dspre funga f at ff f carind hanove h\n",
      "Ag.\n",
      "O be br, mal r foutt'd was, baradoume, ormesthe, shee mesth velludanen e YO:\n",
      "\n",
      "\n",
      "LOREd fonos\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
